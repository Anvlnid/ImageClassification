{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1cI_NgCosOcByiiWSTdp3zsaFpy9NWRCb","authorship_tag":"ABX9TyN0MIjz7vq9CIbcJFFmwPsO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTCNiZ3-QtZ-","executionInfo":{"status":"ok","timestamp":1690379506496,"user_tz":-540,"elapsed":336,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}},"outputId":"1e93ba58-2c6f-452a-eff5-75b863991156"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Image Classification/YOLO/yolov5\n"]}],"source":["%cd /content/drive/MyDrive/Image Classification/YOLO/yolov5"]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"id":"y_7ELXt-UOWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /"],"metadata":{"id":"R0Aq4-d4URqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from glob import glob\n","\n","jpg_list = glob('/content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_img/**/*.jpg', recursive=True)\n","jpeg_list = glob('/content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_img/**/*.jpeg', recursive=True)\n","\n","img_list = jpg_list + jpeg_list\n","img_list[:10]"],"metadata":{"id":"afETCRRjUTU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(img_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItiAHexcXSrp","executionInfo":{"status":"ok","timestamp":1690379593323,"user_tz":-540,"elapsed":437,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}},"outputId":"5380f343-c108-42d9-9bad-2897f6664393"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["193"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_img, val_img = train_test_split(img_list, test_size = 0.2, random_state = 15)"],"metadata":{"id":"KuL5Mr56Pgbm","executionInfo":{"status":"ok","timestamp":1690379616238,"user_tz":-540,"elapsed":426,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_txt/train.txt', 'w') as f:\n","  f.write('\\n'.join(train_img) + 'wn')"],"metadata":{"id":"bZ9dHmj7Xrzw","executionInfo":{"status":"ok","timestamp":1690377959883,"user_tz":-540,"elapsed":335,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_txt/val.txt', 'w') as f:\n","  f.write('\\n'.join(val_img) + 'wn')"],"metadata":{"id":"Q7H-U1ZHX6fN","executionInfo":{"status":"ok","timestamp":1690377960658,"user_tz":-540,"elapsed":428,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Image Classification/YOLO/yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPpxU48fZRBK","executionInfo":{"status":"ok","timestamp":1690378339731,"user_tz":-540,"elapsed":305,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}},"outputId":"f62a4b13-7a72-4eb1-ad0c-80da6aebb0ad"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Image Classification/YOLO/yolov5\n"]}]},{"cell_type":"code","source":["! python train.py --img 416 --batch 16 --epoch 50 --data '/content/drive/MyDrive/Image Classification/data/Mushrooms/train/data.yaml' --cfg '/content/drive/MyDrive/Image Classification/YOLO/yolov5/models/yolov5x.yaml' --weight yolov5x.pt --name mushroom"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mu4jhW6uZUSB","executionInfo":{"status":"ok","timestamp":1690379838650,"user_tz":-540,"elapsed":5562,"user":{"displayName":"Í∂åÏ∞¨Ïö∞ (ÌïòÎäò)","userId":"12336487465890743493"}},"outputId":"90e30b40-baee-433c-9eda-0a3958be1fbd"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ‚ö†Ô∏è 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ‚ö†Ô∏è 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=/content/drive/MyDrive/Image Classification/YOLO/yolov5/models/yolov5x.yaml, data=/content/drive/MyDrive/Image Classification/data/Mushrooms/train/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=mushroom, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n","fatal: cannot change to '/content/drive/MyDrive/Image': No such file or directory\n","YOLOv5 üöÄ 2023-7-26 Python-3.10.6 torch-2.0.1+cu118 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n","  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n","  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n","  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n","  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n","  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n","  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n","  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n","  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n"," 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n"," 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n"," 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n"," 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n"," 24      [17, 20, 23]  1     47103  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n","YOLOv5x summary: 445 layers, 86224543 parameters, 86224543 gradients, 204.6 GFLOPs\n","\n","Transferred 738/745 items from yolov5x.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_txt/train.cache... 153 images, 0 backgrounds, 0 corrupt: 100% 153/153 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Image Classification/data/Mushrooms/train/Mushrooms_txt/val.cache... 38 images, 0 backgrounds, 0 corrupt: 100% 38/38 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.37 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n","Plotting labels to runs/train/mushroom2/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/mushroom2\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/10 [00:00<?, ?it/s]^C\n"]}]},{"cell_type":"code","source":["fname = '/content/drive/MyDrive/Image Classification/data/Poisonous_mushroom/test/Poisonous_mushroom_img/Poisonous_mushroom_01.jpg'\n","!python detect.py --weight '/content/yolov5/runs/train/mushroom4/weights/best.pt' --save-txt --img 416 --conf 0.4 --source \"{fname}\""],"metadata":{"id":"55p5SMHXaGKM"},"execution_count":null,"outputs":[]}]}